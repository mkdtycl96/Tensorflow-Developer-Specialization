{"nbformat":4,"nbformat_minor":0,"metadata":{"coursera":{"course_slug":"introduction-tensorflow","graded_item_id":"1kAlw","launcher_item_id":"PNLYD"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Exercise4-Question.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UncprnB0ymAE"},"source":["Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n","Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n","\n","Hint -- it will work best with 3 convolutional layers."]},{"cell_type":"code","metadata":{"id":"sJVxKI7QqcJu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"b601f326-23a3-4df5-aa49-a26da64057f1","executionInfo":{"status":"ok","timestamp":1588597059785,"user_tz":-330,"elapsed":22452,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}}},"source":["# Mount Google Drive directory to access mnist.npz from tmp2 in Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AyAqwiKhozzg","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","import zipfile\n","from os import path, getcwd, chdir\n","\n","# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n","# environment, then grab happy-or-sad.zip from the Coursera Jupyter Notebook\n","# and place it inside a local folder and edit the path to that location\n","\n","\n","# Path for Coursera Jupyter autograder:\n","# path = f\"{getcwd()}/../tmp2/happy-or-sad.zip\"\n","\n","# Path to happy-or-sad.zip in Google Drive:\n","path = f\"{getcwd()}/drive/My Drive/TensorFlow In Practice/1. Introduction to TensorFlow/Exercises/tmp2/happy-or-sad.zip\"\n","\n","zip_ref = zipfile.ZipFile(path, 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPRs_pXTozzu","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: train_happy_sad_model\n","def train_happy_sad_model():\n","    # Please write your code only where you are indicated.\n","    # please do not remove # model fitting inline comments.\n","\n","    DESIRED_ACCURACY = 0.999\n","\n","    class myCallback(tf.keras.callbacks.Callback):\n","      def on_epoch_end(self, epoch, logs={}):\n","        # Change 'accuracy' to 'acc' for the Coursera autograder!\n","        if(logs.get('accuracy')>DESIRED_ACCURACY): \n","          print(\"\\nReached 99.9% accuracy so cancelling training!\")\n","          self.model.stop_training = True\n","\n","    callbacks = myCallback()\n","    \n","    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n","    model = tf.keras.models.Sequential([\n","        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n","        # This is the first convolution\n","        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        # The second convolution\n","        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2,2),\n","        # The third convolution\n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2,2),\n","      \n","        # Flatten the results to feed into a DNN\n","        tf.keras.layers.Flatten(),\n","        # 512 neuron hidden layer\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","    from tensorflow.keras.optimizers import RMSprop\n","\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=RMSprop(lr=0.001),\n","                  metrics=['accuracy'])\n","        \n","\n","    # This code block should create an instance of an ImageDataGenerator called train_datagen \n","    # And a train_generator by calling train_datagen.flow_from_directory\n","\n","    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","    train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","    # Please use a target_size of 150 X 150.\n","    train_generator = train_datagen.flow_from_directory(\n","        '/tmp/h-or-s',\n","        target_size=(150, 150),\n","        batch_size=10,\n","        class_mode='binary')\n","    # Expected output: 'Found 80 images belonging to 2 classes'\n","\n","    # This code block should call model.fit_generator and train for\n","    # a number of epochs.\n","    # model fitting\n","    history = model.fit_generator(\n","          train_generator,\n","          steps_per_epoch=8,\n","          epochs=15,\n","          verbose=1,\n","          callbacks=[callbacks])\n","    # model fitting\n","    # Change 'accuracy' to 'acc' for the Coursera autograder!\n","    return history.history['accuracy'][-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Bm8lN2_ozz6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"829fb783-ff30-4aa4-983b-37a8eef7f4da","executionInfo":{"status":"ok","timestamp":1588597497240,"user_tz":-330,"elapsed":24043,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}}},"source":["# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\n","train_happy_sad_model()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n","Epoch 1/15\n","8/8 [==============================] - 2s 242ms/step - loss: 2.2697 - accuracy: 0.5125\n","Epoch 2/15\n","8/8 [==============================] - 2s 240ms/step - loss: 0.4238 - accuracy: 0.8250\n","Epoch 3/15\n","8/8 [==============================] - 2s 243ms/step - loss: 0.1871 - accuracy: 0.9250\n","Epoch 4/15\n","8/8 [==============================] - 2s 247ms/step - loss: 0.1873 - accuracy: 0.8875\n","Epoch 5/15\n","8/8 [==============================] - 2s 243ms/step - loss: 0.1219 - accuracy: 0.9375\n","Epoch 6/15\n","8/8 [==============================] - 2s 244ms/step - loss: 0.0855 - accuracy: 0.9750\n","Epoch 7/15\n","8/8 [==============================] - 2s 243ms/step - loss: 0.0561 - accuracy: 0.9625\n","Epoch 8/15\n","8/8 [==============================] - 2s 242ms/step - loss: 0.1126 - accuracy: 0.9250\n","Epoch 9/15\n","8/8 [==============================] - 2s 247ms/step - loss: 0.1954 - accuracy: 0.9000\n","Epoch 10/15\n","8/8 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.0000\n","Reached 99.9% accuracy so cancelling training!\n","8/8 [==============================] - 2s 241ms/step - loss: 0.0163 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":7}]}]}