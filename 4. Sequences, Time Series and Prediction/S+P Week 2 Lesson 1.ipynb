{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"S+P Week 2 Lesson 1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO","colab_type":"code","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s6eq-RBcQ_Zr","colab":{}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BOjujz601HcS","outputId":"1af09232-1995-46a6-f282-9fb8d56c1964","executionInfo":{"status":"ok","timestamp":1590935049524,"user_tz":-330,"elapsed":4336,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"asEdslR_05O_","outputId":"d1cfe0b7-53ad-455c-e434-37d816d07fc1","executionInfo":{"status":"ok","timestamp":1590935049525,"user_tz":-330,"elapsed":4328,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["dataset = tf.data.Dataset.range(10)\n","for val in dataset:\n","   print(val.numpy())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lrv_ghSt1lgQ","outputId":"9af8b783-8c7d-4ae4-8b70-9cf888d4ba69","executionInfo":{"status":"ok","timestamp":1590935049527,"user_tz":-330,"elapsed":4320,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1)\n","for window_dataset in dataset:\n","  for val in window_dataset:\n","    print(val.numpy(), end=\" \")\n","  print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 1 2 3 4 \n","1 2 3 4 5 \n","2 3 4 5 6 \n","3 4 5 6 7 \n","4 5 6 7 8 \n","5 6 7 8 9 \n","6 7 8 9 \n","7 8 9 \n","8 9 \n","9 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QLEq6MG-2DN2","outputId":"9ffbcc83-8dd1-4a5f-9927-2150b7b013cd","executionInfo":{"status":"ok","timestamp":1590935049528,"user_tz":-330,"elapsed":4311,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1, drop_remainder=True)\n","for window_dataset in dataset:\n","  for val in window_dataset:\n","    print(val.numpy(), end=\" \")\n","  print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 1 2 3 4 \n","1 2 3 4 5 \n","2 3 4 5 6 \n","3 4 5 6 7 \n","4 5 6 7 8 \n","5 6 7 8 9 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9PsGELODIPJs","colab_type":"text"},"source":["**Pro tip:** lambda window means the follwing function is in terms of window. flat_map applies this function to dataset and then flattens the result."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PJ9CAHlJ2ODe","outputId":"02446da1-a9dc-4c3c-9377-d4659d7c1927","executionInfo":{"status":"ok","timestamp":1590935716146,"user_tz":-330,"elapsed":1598,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(5)) # window is a tensor!\n","for window in dataset:\n","  print(window.numpy()) # Need numpy lists for ML!"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0 1 2 3 4]\n","[1 2 3 4 5]\n","[2 3 4 5 6]\n","[3 4 5 6 7]\n","[4 5 6 7 8]\n","[5 6 7 8 9]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1B33YpOfK4WF","colab_type":"text"},"source":["**Note:** We now want to split these sequences into features and labels. We want to input everything but the last element and have our model predict the last element."]},{"cell_type":"markdown","metadata":{"id":"ejUOkVzuKbzW","colab_type":"text"},"source":["**Pro tip:** window[:-1] is everything up to (but not including) the last element. window[-1:] is everything from the last element to the end, which is just the last element."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DryEZ2Mz2nNV","outputId":"8e30692c-9640-4b8a-824c-e8fab00c623c","executionInfo":{"status":"ok","timestamp":1590935049530,"user_tz":-330,"elapsed":4294,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(5))\n","dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n","for x,y in dataset:\n","  print(x.numpy(), y.numpy())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0 1 2 3] [4]\n","[1 2 3 4] [5]\n","[2 3 4 5] [6]\n","[3 4 5 6] [7]\n","[4 5 6 7] [8]\n","[5 6 7 8] [9]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ARxtJox7Oy5B","colab_type":"text"},"source":["**Note:** We now shuffle the sequences so that we don't accidentally introduce a bias towards particular orders of sequences. shuffle(buffer_size) randomly shuffles the elements of this dataset.\n","\n","This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n","\n","For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then shuffle will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.\n","\n","In this case, we have 6 sequences and we use a buffer_size of 10."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1tl-0BOKkEtk","outputId":"ec00ea15-967c-49c7-b64b-489601d5084f","executionInfo":{"status":"ok","timestamp":1590935049531,"user_tz":-330,"elapsed":4285,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(5))\n","dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n","dataset = dataset.shuffle(buffer_size=10)\n","for x,y in dataset:\n","  print(x.numpy(), y.numpy())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[4 5 6 7] [8]\n","[0 1 2 3] [4]\n","[1 2 3 4] [5]\n","[3 4 5 6] [7]\n","[2 3 4 5] [6]\n","[5 6 7 8] [9]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yMPWzsr4Q7tf","colab_type":"text"},"source":["**Pro tip:** prefetch creates a Dataset that prefetches elements from the main dataset.\n","\n","Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n","\n","The Dataset.prefetch(m) transformation prefetches m elements of its direct input. In this case, since its direct input is dataset.batch(n) and each element of that dataset is a batch (of n elements), it will prefetch m batches."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Wa0PNwxMGapy","outputId":"412b98f2-adfb-4d71-87c4-8b4a7aea61a8","executionInfo":{"status":"ok","timestamp":1590935049532,"user_tz":-330,"elapsed":4277,"user":{"displayName":"Agni Iyer","photoUrl":"https://lh5.googleusercontent.com/-t_0Yj_TZMvc/AAAAAAAAAAI/AAAAAAAABNo/ntatgaKFYUI/s64/photo.jpg","userId":"12872450379171189898"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset = tf.data.Dataset.range(10)\n","dataset = dataset.window(5, shift=1, drop_remainder=True)\n","dataset = dataset.flat_map(lambda window: window.batch(5))\n","dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n","dataset = dataset.shuffle(buffer_size=10)\n","dataset = dataset.batch(2).prefetch(1)\n","for x,y in dataset:\n","  print(\"x = \", x.numpy())\n","  print(\"y = \", y.numpy())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x =  [[0 1 2 3]\n"," [3 4 5 6]]\n","y =  [[4]\n"," [7]]\n","x =  [[2 3 4 5]\n"," [4 5 6 7]]\n","y =  [[6]\n"," [8]]\n","x =  [[1 2 3 4]\n"," [5 6 7 8]]\n","y =  [[5]\n"," [9]]\n"],"name":"stdout"}]}]}